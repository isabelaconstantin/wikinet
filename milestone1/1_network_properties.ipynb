{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTDS'18 milestone 1: network collection and properties\n",
    "[Effrosyni Simou](https://lts4.epfl.ch/simou), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: 37\n",
    "* Students: Adélie Eliane Garin, Celia Camille Hacker, Isabela Constantin, Michael Spieler\n",
    "* Dataset: Wikipedia https://snap.stanford.edu/data/wikispeedia/wikispeedia_paths-and-graph.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to three sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this milestone is to start getting acquainted to the network that you will use for this class. In the first part of the milestone you will import your data using [Pandas](http://pandas.pydata.org) and you will create the adjacency matrix using [Numpy](http://www.numpy.org). This part is project specific. In the second part you will have to compute some basic properties of your network. **For the computation of the properties you are only allowed to use the packages that have been imported in the cell below.** You are not allowed to use any graph-specific toolboxes for this milestone (such as networkx and PyGSP). Furthermore, the aim is not to blindly compute the network properties, but to also start to think about what kind of network you will be working with this semester. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for replicating Q8\n",
    "np.random.seed(seed=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Import your data and manipulate them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Load your data in a Panda dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you should define and understand what are your nodes, what features you have and what are your labels. Please provide below a Panda dataframe where each row corresponds to a node with its features and labels. For example, in the the case of the Free Music Archive (FMA) Project, each row of the dataframe would be of the following form:\n",
    "\n",
    "\n",
    "| Track   |  Feature 1  | Feature 2 | . . . | Feature 518|  Label 1 |  Label 2 |. . .|Label 16|\n",
    "|:-------:|:-----------:|:---------:|:-----:|:----------:|:--------:|:--------:|:---:|:------:|\n",
    "|         |             |           |       |            |          |          |     |        |\n",
    "\n",
    "It is possible that in some of the projects either the features or the labels are not available. This is OK, in that case just make sure that you create a dataframe where each of the rows corresponds to a node and its associated features or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../wikispeedia_paths-and-graph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_utf8(string):\n",
    "    parts = string.encode('ascii').split(b'%')\n",
    "    decoded = [bytes.fromhex(part[:2].decode('ascii')) + part[2:] for part in parts[1:]]\n",
    "    raw = parts[0] + b''.join(decoded)\n",
    "    return raw.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = pd.read_csv(data_path+ 'articles.tsv', sep='\\t', names=['article'], skiprows=11)\n",
    "articles.head(10)\n",
    "articles['article'] = articles['article'].apply(decode_utf8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Édouard_Manet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Éire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Óengus_I_of_the_Picts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>€2_commemorative_coins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13th_century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  article\n",
       "0       Áedán_mac_Gabráin\n",
       "1                   Åland\n",
       "2           Édouard_Manet\n",
       "3                    Éire\n",
       "4   Óengus_I_of_the_Picts\n",
       "5  €2_commemorative_coins\n",
       "6            10th_century\n",
       "7            11th_century\n",
       "8            12th_century\n",
       "9            13th_century"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>[subject.History.British_History.British_Histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>[subject.People.Historical_figures]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Åland</td>\n",
       "      <td>[subject.Countries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Åland</td>\n",
       "      <td>[subject.Geography.European_Geography.European...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Édouard_Manet</td>\n",
       "      <td>[subject.People.Artists]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article                                           category\n",
       "0  Áedán_mac_Gabráin  [subject.History.British_History.British_Histo...\n",
       "1  Áedán_mac_Gabráin                [subject.People.Historical_figures]\n",
       "2              Åland                                [subject.Countries]\n",
       "3              Åland  [subject.Geography.European_Geography.European...\n",
       "4      Édouard_Manet                           [subject.People.Artists]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.read_csv(data_path+ 'categories.tsv', sep='\\t', names=['category'], skiprows=12).reset_index()\n",
    "categories.rename(columns={\"index\": \"article\"}, inplace=True)\n",
    "categories['article'] = categories['article'].apply(decode_utf8) \n",
    "categories['category'] = categories['category'].apply(lambda x: [x])\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15th_Marine_Expeditionary_Unit</td>\n",
       "      <td>[subject.History.Military_History_and_War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16_Cygni</td>\n",
       "      <td>[subject.Science.Physics.Space_Astronomy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16_Cygni_Bb</td>\n",
       "      <td>[subject.Science.Physics.Space_Astronomy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          article                                    category\n",
       "0                    10th_century           [subject.History.General_history]\n",
       "1                    11th_century           [subject.History.General_history]\n",
       "2                    12th_century           [subject.History.General_history]\n",
       "3                    13th_century           [subject.History.General_history]\n",
       "4                    14th_century           [subject.History.General_history]\n",
       "5  15th_Marine_Expeditionary_Unit  [subject.History.Military_History_and_War]\n",
       "6                    15th_century           [subject.History.General_history]\n",
       "7                        16_Cygni   [subject.Science.Physics.Space_Astronomy]\n",
       "8                     16_Cygni_Bb   [subject.Science.Physics.Space_Astronomy]\n",
       "9                    16th_century           [subject.History.General_history]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = categories.groupby(by= 'article').agg({'category': 'sum'}).reset_index()\n",
    "article_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject.History.British_History.British_History_1500_and_before_including_Roman_Britain',\n",
       " 'subject.People.Historical_figures']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "article_df.loc[article_df['article'] == 'Áedán_mac_Gabráin']['category'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4598, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used `article_df` instead of `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    " \n",
    "#features = # the pandas dataframe with the features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create the adjacency matrix of your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that there are edges connecting the attributed nodes that you organized in the dataframe above. The connectivity of the network is captured by the adjacency matrix $W$. If $N$ is the number of nodes, the adjacency matrix is an $N \\times N$ matrix where the value of $W(i,j)$ is the weight of the edge connecting node $i$ to node $j$.  \n",
    "\n",
    "There are two possible scenarios for your adjacency matrix construction, as you already learned in the tutorial by Benjamin:\n",
    "\n",
    "1) The edges are given to you explicitly. In this case you should simply load the file containing the edge information and parse it in order to create your adjacency matrix. See how to do that in the  [graph from edge list]() demo.\n",
    "\n",
    "2) The edges are not given to you. In that case you will have to create a feature graph. In order to do that you will have to chose a distance that will quantify how similar two nodes are based on the values in their corresponding feature vectors. In the [graph from features]() demo Benjamin showed you how to build feature graphs when using Euclidean distances between feature vectors. Be curious and explore other distances as well! For instance, in the case of high-dimensional feature vectors, you might want to consider using the cosine distance. Once you compute the distances between your nodes you will have a fully connected network. Do not forget to sparsify by keeping the most important edges in your network.\n",
    "\n",
    "Follow the appropriate steps for the construction of the adjacency matrix of your network and provide it in the Numpy array ``adjacency`` below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>Bede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>Columba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>Dál_Riata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>Great_Britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article           link\n",
       "0  Áedán_mac_Gabráin           Bede\n",
       "1  Áedán_mac_Gabráin        Columba\n",
       "2  Áedán_mac_Gabráin      Dál_Riata\n",
       "3  Áedán_mac_Gabráin  Great_Britain\n",
       "4  Áedán_mac_Gabráin        Ireland"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = pd.read_csv(data_path + 'links.tsv', sep='\\t', names=['article', 'link'], skiprows=12)\n",
    "edges['article'] = edges['article'].apply(decode_utf8) \n",
    "edges['link'] = edges['link'].apply(decode_utf8) \n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Directdebit', 'Friend_Directdebit', 'Pikachu'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note there are links being linked but not having a category\n",
    "set(list(edges['link'])) - set(list(article_df['article']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friend_Directdebit', 'Pikachu', 'Sponsorship_Directdebit'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note there are links that link to other articles but dont have a category\n",
    "set(list(edges['article'])) - set(list(article_df['article']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add these pages to our article_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n"
     ]
    }
   ],
   "source": [
    "article_df = article_df.merge(edges.drop(columns=['link']).drop_duplicates(), \\\n",
    "                              right_on= 'article', left_on= 'article', how='outer' )\n",
    "print(len(article_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14th_century</td>\n",
       "      <td>[subject.History.General_history]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article                           category\n",
       "0  10th_century  [subject.History.General_history]\n",
       "1  11th_century  [subject.History.General_history]\n",
       "2  12th_century  [subject.History.General_history]\n",
       "3  13th_century  [subject.History.General_history]\n",
       "4  14th_century  [subject.History.General_history]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_temp = edges.drop(columns=['article']).drop_duplicates().rename(columns = {'link': 'article'})\n",
    "article_df = article_df.merge(edges_temp, right_on= 'article', left_on= 'article', how='outer')\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4602, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13th_century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14th_century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx       article\n",
       "0    0  10th_century\n",
       "1    1  11th_century\n",
       "2    2  12th_century\n",
       "3    3  13th_century\n",
       "4    4  14th_century"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = article_df.reset_index(level=0)\n",
    "nodes.drop(columns=['category'], inplace=True)\n",
    "nodes.rename(columns={'index':'idx'}, inplace=True)\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map nodes to indicies\n",
    "node_map = dict(zip( nodes.article, nodes.idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_idx</th>\n",
       "      <th>link_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4592</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4592</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4592</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4592</td>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4592</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_idx  link_idx\n",
       "0         4592       524\n",
       "1         4592       966\n",
       "2         4592      1260\n",
       "3         4592      1763\n",
       "4         4592      2140"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges['article_idx'] = edges['article'].apply(lambda x: node_map[x])\n",
    "edges['link_idx'] = edges['link'].apply(lambda x: node_map[x])\n",
    "edges = edges.drop(columns=['article', 'link'])\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes = len(nodes)\n",
    "adjacency = np.zeros((n_nodes, n_nodes), dtype=int)\n",
    "\n",
    "for idx, row in edges.iterrows():\n",
    "    if np.isnan(row.link_idx):\n",
    "        continue\n",
    "    i, j = int(row.article_idx), int(row.link_idx)\n",
    "    \n",
    "    # TODO: which index is which? this matters since it is a directed graph \n",
    "    # -> node i (row i) links to node j (column j)\n",
    "    adjacency[i, j] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4602"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_idx</th>\n",
       "      <th>link_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_idx  link_idx\n",
       "183            1      3002"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks \n",
    "adjacency[1][3002] == 1 # there is a link between page 1 and 3002\n",
    "edges.loc[(edges['article_idx'] == 1) & (edges['link_idx'] ==  3002)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to plot the (weighted) adjacency matrix of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1.05,'adjacency matrix')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.spy(adjacency)\n",
    "plt.title('adjacency matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the maximum number of links $L_{max}$ in a network with $N$ nodes (where $N$ is the number of nodes in your network)? How many links $L$ are there in your collected network? Comment on the sparsity of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 119882, L_max = 21173802, sparsity = 0.0057\n"
     ]
    }
   ],
   "source": [
    "n_nodes = len(nodes)\n",
    "\n",
    "L = np.sum(adjacency)\n",
    "# This sums the links in the directed graph: if we have A->B and B->A then it counts as two links. \n",
    "# If we wanted this to count as one link we would have to do the same computation on the undirected adjacency matrix and divide by 2 \n",
    "\n",
    "L_max_undirected = int(n_nodes*(n_nodes-1)/2)\n",
    "# Again, n_nodes*(n_nodes-1)/2) is the undirected case. In the directed case there can be two links between a node A and a node B. \n",
    "L_max = int(n_nodes*(n_nodes-1))\n",
    "# We multiplied by 2 because the maximal number of links is \"doubled\" by A->B and B->A (need to count them twice)\n",
    "\n",
    "print('L = {}, L_max = {}, sparsity = {:.4f}'.format(L, L_max, L/L_max))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer* \n",
    "Clearly L << L_max as in many real world networks. It makes sense here as many wikipedia pages (like 'cats') will not be linked to other unrelated subjects (like 'spaceships') ;)\n",
    "We can also see the sparsity in the adjacency matrix above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Is your graph directed or undirected? If it is directed, convert it to an undirected graph by symmetrizing the adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "*Answer:*\n",
    "Our graph is directed since a URL link on a Wiki page is directed.\n",
    "To make it undirected the adjacency matrix can be OR-ed with its transposed such that it is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117b5f390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_undirected = np.maximum(adjacency, adjacency.T)\n",
    "plt.spy(adjacency_undirected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "In the cell below save the features dataframe and the **symmetrized** adjacency matrix. You can use the Pandas ``to_csv`` to save the ``features`` and Numpy's ``save`` to save the ``adjacency``. We will reuse those in the following milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "edges.to_csv('edges.csv')\n",
    "article_df.to_csv('article_dv.csv')\n",
    "#np.save('adjacency_sym.npy', adjacency_sym)\n",
    "np.savez_compressed('adjacency_undirected.npz', adjacency_undirected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: For the following questions we consider only the undirected graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Are the edges of your graph weighted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "No, links on a Wikipedia page are not weighted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the degree distibution of your network? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree =  np.sum(adjacency_undirected, axis=0)\n",
    "\n",
    "assert len(degree) == n_nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see the histogram of the degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.ones_like(degree) / float(n_nodes)\n",
    "plt.hist(degree, weights=weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average degree in the network is 46.32420686657975\n"
     ]
    }
   ],
   "source": [
    "# Considering the undirected graph\n",
    "L_undirected= np.sum(adjacency_undirected)/2\n",
    "# We compute the number of links in the undirected case as this will differ from the directed case\n",
    "\n",
    "\n",
    "print ('The average degree in the network is ' + str(2*L_undirected/n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Comment on the degree distribution of your network. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "*Answer*\n",
    "We have 4602 nodes with an average degree of 46.32 (in the undirected network). Compared to other internet networks this is much higher. For example the network consisting of webpages, the average is only 4.6. It is not surprising in the case of Wikipedia as there are many links in every wikipedia page.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Write a function that takes as input the adjacency matrix of a graph and determines whether the graph is connected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a queue data structure for BFS\n",
    "class Queue:\n",
    "    def __init__(self):\n",
    "        self.elem = []\n",
    "\n",
    "    def isEmpty(self):\n",
    "        return (len(self.elem) == 0)\n",
    "\n",
    "    def enqueue(self, item):\n",
    "        self.elem.append(item)\n",
    "\n",
    "    def dequeue(self):\n",
    "        return self.elem.pop(0)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pseudocode: start BFS from node 0. if by the end the number of visited nodes < nb of nodes \n",
    "# then the graph is disconnected\n",
    "def connected_graph(adjacency):\n",
    "    \"\"\"Determines whether a graph is connected.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the graph is connected, False otherwise.\n",
    "    \"\"\"\n",
    "    start_node = 0\n",
    "    node_q = Queue()\n",
    "    node_q.enqueue(start_node)\n",
    "    visited = set()\n",
    "    visited.add(start_node)\n",
    "    nb_visited = 1\n",
    "    while (node_q.isEmpty() == False ):\n",
    "        curr = node_q.dequeue()\n",
    "        successors = adjacency[curr].nonzero()[0]\n",
    "        for succ in successors:\n",
    "            if succ not in visited:\n",
    "                node_q.enqueue(succ)\n",
    "                visited.add(succ)\n",
    "                nb_visited += 1\n",
    "    connected = (nb_visited == adjacency.shape[0])\n",
    "    if connected:\n",
    "        print('The graph is connected')\n",
    "    else:\n",
    "        print('The graph is not connected')\n",
    "        print('The number of visited nodes starting from ', start_node, ' is ', nb_visited)\n",
    "    return connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your graph connected? Run the ``connected_graph`` function to determine your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph is not connected\n",
      "The number of visited nodes starting from  0  is  4589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here.\n",
    "connected_graph(adjacency_undirected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Write a function that extracts the connected components of a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar approach as in previous question, but add an outer for loop in order to go through all connected \n",
    "# of the graph \n",
    "def find_components(adjacency):\n",
    "    \"\"\"Find the connected components of a graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of numpy arrays\n",
    "        A list of adjacency matrices, one per connected component.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency.shape[0]\n",
    "    components = []\n",
    "    is_visited_global = np.zeros(n_nodes, dtype=bool)\n",
    "    for node in range(n_nodes):\n",
    "        if is_visited_global[node] == False:\n",
    "            start_node = node\n",
    "            node_q = Queue()\n",
    "            node_q.enqueue(start_node)\n",
    "            visited = set()\n",
    "            visited.add(start_node)\n",
    "            is_visited_global[start_node]= True\n",
    "            while (node_q.isEmpty() == False ):\n",
    "                curr = node_q.dequeue()\n",
    "                successors = adjacency[curr].nonzero()[0]\n",
    "                for succ in successors:\n",
    "                    if succ not in visited:\n",
    "                        node_q.enqueue(succ)\n",
    "                        visited.add(succ)\n",
    "                        is_visited_global[succ] = True\n",
    "            # now a component has been found, add it to the list of adj matricies\n",
    "            idx_comp = list(visited)\n",
    "            components.append(adjacency[idx_comp][:,idx_comp])\n",
    "    return components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "* we could have used a single function to do BFS over a connected component in both Q 7 and 8 to avoid code repetition, but to go by the required API, we decided to stick to writing two independent functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components is your network composed of? What is the size of the largest connected component? Run the ``find_components`` function to determine your answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of connected components in the graph is  12\n",
      "The largest component has  4589  nodes\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "connected_comp = find_components(adjacency_undirected)\n",
    "print('The number of connected components in the graph is ', len(connected_comp))\n",
    "idx_larg_comp = np.argmax([len(adj) for adj in connected_comp])\n",
    "adj_larg_comp = connected_comp[idx_larg_comp]\n",
    "nb_nodes_larg_comp = len(adj_larg_comp)\n",
    "print('The largest component has ', nb_nodes_larg_comp, ' nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Write a function that takes as input the adjacency matrix and a node (`source`) and returns the length of the shortest path between that node and all nodes in the graph using Dijkstra's algorithm. **For the purposes of this assignment we are interested in the hop distance between nodes, not in the sum of weights. **\n",
    "\n",
    "Hint: You might want to mask the adjacency matrix in the function ``compute_shortest_path_lengths`` in order to make sure you obtain a binary adjacency matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  3., inf, inf])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implements the Djikstra algorithm from Wikipedia: https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Algorithm\n",
    "# TODO: not shure if this is correct. also, it seems that some of the nodes are not reachable\n",
    "def compute_shortest_path_lengths(adjacency, source):\n",
    "    \"\"\"Compute the shortest path length between a source node and all nodes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    source: int\n",
    "        The source node. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of ints\n",
    "        The length of the shortest path from source to all nodes. Returned list should be of length n_nodes.\n",
    "    \"\"\"\n",
    "    n_nodes = adjacency.shape[0]\n",
    "    MAX_DIST = np.inf\n",
    "    unvisited = set(np.arange(n_nodes))\n",
    "    shortest_path_lengths = np.full(n_nodes, MAX_DIST)\n",
    "\n",
    "    shortest_path_lengths[source] = 0\n",
    "    while unvisited:\n",
    "        unvisited_list = list(unvisited)\n",
    "        current = unvisited_list[np.argmin(shortest_path_lengths[unvisited_list])]\n",
    "        adjacency_list = adjacency[current]\n",
    "        neighbors = set(np.nonzero(adjacency_list)[0])\n",
    "        for n in neighbors.intersection(unvisited):\n",
    "            path_len = shortest_path_lengths[current] + 1\n",
    "            if shortest_path_lengths[n] > path_len:\n",
    "                shortest_path_lengths[n] = path_len\n",
    "\n",
    "        unvisited.remove(current)\n",
    "    \n",
    "    return shortest_path_lengths\n",
    "\n",
    "short_node_0 = compute_shortest_path_lengths(adjacency_undirected, 0)\n",
    "short_node_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 435,  962, 1227, 2534, 3341, 3631, 3913, 4278, 4322, 4469, 4598,\n",
       "        4600, 4601]),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example, list of nodes not reachable by 0 \n",
    "np.where(short_node_0 == np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "The diameter of the graph is the length of the longest shortest path between any pair of nodes. Use the above developed function to compute the diameter of the graph (or the diameter of the largest connected component of the graph if the graph is not connected). If your graph (or largest connected component) is very large, computing the diameter will take very long. In that case downsample your graph so that it has 1.000 nodes. There are many ways to reduce the size of a graph. For the purposes of this milestone you can chose to randomly select 1.000 nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected component has  1072  nodes\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "# take the largest connected comp\n",
    "# sample randomly approx 1000 nodes and extract the largest comp from the subsampled graph\n",
    "sample_idx = np.random.choice(nb_nodes_larg_comp, size = 1100, replace=False)\n",
    "adj_sample = adj_larg_comp[sample_idx][:,sample_idx]\n",
    "components_sample = find_components(adj_sample)\n",
    "idx_larg_comp = np.argmax([len(adj) for adj in components_sample])\n",
    "adj_sample_conn = components_sample[idx_larg_comp]\n",
    "# compute the longest shortest path for each node.\n",
    "nb_n_sample = len(adj_sample_conn)\n",
    "print('The selected component has ', nb_n_sample, ' nodes')\n",
    "longest_shortest_paths = [np.max(compute_shortest_path_lengths(adj_sample_conn, node)) for node in range(nb_n_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diameter of the largest connected comp of the sub-sampled graph is  7.0\n"
     ]
    }
   ],
   "source": [
    "print('The diameter of the largest connected comp of the sub-sampled graph is ', np.max(longest_shortest_paths) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Write a function that takes as input the adjacency matrix, a path length, and two nodes (`source` and `target`), and returns the number of paths of the given length between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for answering this question, we used the following theorem:\n",
    "\n",
    "Let G a simple undirected graph and A its adjacency matrix. \n",
    "The $(i,j)$ th entry of $A^k$ counts the number of walks of length $k$ having source and end vertices\n",
    "$i$ and $j$ respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_paths(adjacency, source, target, length):\n",
    "    \"\"\"Compute the number of paths of a given length between a source and target node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    source: int\n",
    "        The source node. A number between 0 and n_nodes-1.\n",
    "    target: int\n",
    "        The target node. A number between 0 and n_nodes-1.\n",
    "    length: int\n",
    "        The path length to be considered.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of paths.\n",
    "    \"\"\"\n",
    "    n_paths=int(np.linalg.matrix_power(adjacency, length)[source][target])\n",
    "    \n",
    "    \n",
    "    return n_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function on 5 pairs of nodes, with different lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: change output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(compute_paths(adjacency_undirected, 0, 10, 1))\n",
    "print(compute_paths(adjacency_undirected, 0, 10, 2))\n",
    "print(compute_paths(adjacency_undirected, 0, 10, 3))\n",
    "print(compute_paths(adjacency_undirected, 23, 67, 2))\n",
    "print(compute_paths(adjacency_undirected, 15, 93, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "How many paths of length 3 are there in your graph? Hint: calling the `compute_paths` function on every pair of node is not an efficient way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702162721\n"
     ]
    }
   ],
   "source": [
    "adjacency_undirected_power_3=np.linalg.matrix_power(adjacency_undirected,3)\n",
    "\n",
    "print(int(np.sum(adjacency_undirected_power_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Write a function that takes as input the adjacency matrix of your graph (or of the largest connected component of your graph) and a node and returns the clustering coefficient of that node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: check Q 13 and 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  we modified the API to account for the matrix multiplication, in order to do it just once. \n",
    "def compute_clustering_coefficient(adjacency, node, power_matrix=None):\n",
    "    \"\"\"Compute the clustering coefficient of a node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    node: int\n",
    "        The node whose clustering coefficient will be computed. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The clustering coefficient of the node. A number between 0 and 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    degree = np.sum(adjacency, axis = 0)\n",
    "    L = np.linalg.matrix_power(adjacency,3)[node][node]/2\n",
    "    k= degree[node]\n",
    "    \n",
    "    clustering_coefficient= L/(k*(k-1)/2)\n",
    "    \n",
    "    return clustering_coefficient, power_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff, power_mat = compute_clustering_coefficient(adj_larg_comp,0 )\n",
    "print('The clustering coeff of node 0 is ', coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "What is the average clustering coefficient of your graph (or of the largest connected component of your graph if your graph is disconnected)? Use the function ``compute_clustering_coefficient`` to determine your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average clustering coeffcient of our network is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celiahacker/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Modifiy this once we have the largest connected component: some nodes are apparently completely isolated \n",
    "average_clustering_coefficient=0 \n",
    "for i in range(nb_nodes_larg_comp):\n",
    "    coeff, _ = compute_clustering_coefficient(adj_larg_comp, i, power_mat)\n",
    "    average_clustering_coefficient+= coeff\n",
    "    \n",
    "average_clustering_coefficient=average_clustering_coefficient/nb_nodes_larg_comp\n",
    "\n",
    "print('The average clustering coeffcient of our network is '+str(average_clustering_coefficient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 84,  83, 111, ...,  14,   1,   1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.165932371461522e-08"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another possible solution without using the function defined above and without loop\n",
    "# Modifiy this once we have the largest connected component \n",
    "np.sum(np.diag(adj_larg_comp)/(2*degree_larg_conn_comp*(nb_nodes_larg_comp-1)))/nb_nodes_larg_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 1, 0, 1, 0],\n",
       "        [1, 0, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 1, 0],\n",
       "        [1, 0, 1, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 1, 0]])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connected graph\n",
    "adj_undir = np.array([[0, 1, 1, 0, 1, 0],\n",
    "       [1, 0, 1, 1, 0, 1],\n",
    "       [1, 1, 0, 0, 1, 0],\n",
    "       [0, 1, 0, 0, 1, 0],\n",
    "       [1, 0, 1, 1, 0, 1],\n",
    "       [0, 1, 0, 0, 1, 0]])\n",
    "find_components(adj_undir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0]]), array([[0, 1, 1, 0, 1],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 1, 1, 0, 1],\n",
       "        [1, 0, 0, 1, 0]])]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disconnect 0 \n",
    "adj_undir_2 = np.array([[0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 1],\n",
    "       [0, 1, 0, 0, 1, 0],\n",
    "       [0, 1, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 1, 0, 1],\n",
    "       [0, 1, 0, 0, 1, 0]])\n",
    "find_components(adj_undir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0]]), array([[0, 1, 1, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 0, 1],\n",
       "        [0, 1, 1, 0]]), array([[0]])]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disconnect 5\n",
    "adj_undir_3 = np.array([[0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0],\n",
    "       [0, 1, 0, 0, 1, 0],\n",
    "       [0, 1, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0]])\n",
    "find_components(adj_undir_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0]]), array([[0]]), array([[0]])]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have all disconnected\n",
    "adj_undir_4 = np.array([[0, 0, 0],\n",
    "       [0, 0, 0],\n",
    "       [0, 0, 0]])\n",
    "find_components(adj_undir_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
