{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 2: network models\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Hermina Petric Maretic](https://people.epfl.ch/hermina.petricmaretic), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students\n",
    "\n",
    "* Team: 37\n",
    "* Students: Isabela Constantin, Adélie Garin, Celia Hacker, Michael Spieler\n",
    "* Dataset: Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* In the first part, you cannot import any other library than we imported. In the second part, you are allowed to import any library you want.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this milestone is to explore various random network models, analyse their properties and compare them to your network. In the first part of the milestone you will implement two random graph models and try to fit them to your network. In this part you are not allowed to use any additional package. In the second part of the milestone you will choose a third random graph model that you think shares some properties with your network. You will be allowed to use additional packages to construct this network, but you must explain your network choice. Finally, make your code as clean as possible, and keep your textual answers short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0\n",
    "\n",
    "Import the adjacency matrix of your graph that you constructed in milestone 1, as well as the number of nodes and edges of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the adjacency matrix we will work with is the adjacency matrix of the largest weakly connected component \n",
    "adjacency_disconnected =  np.load('adjacency_undirected.npz')['arr_0'] # the adjacency matrix\n",
    "adjacency = np.load('largest_wcc.npz')['arr_0'] \n",
    "n_nodes =  adjacency.shape[0] # the number of nodes in the network\n",
    "n_edges =  int(np.sum(adjacency)/2) # the number of edges in the network\n",
    "print('the network has {} nodes and {} edges'.format(n_nodes, n_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "**For the computation of this part of the milestone you are only allowed to use the packages that have been imported in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Create a function that constructs an Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos_renyi(n, proba, seed=None):\n",
    "    \"\"\"Create an instance from the Erdos-Renyi graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    p: float\n",
    "        Edge probability. A number between 0 and 1.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    adjacency = np.zeros((n,n))\n",
    "    adjacency[np.triu_indices(n, k=1)] = np.random.choice(2, int(n*(n-1)/2), p=[1-proba, proba])\n",
    "    adjacency = adjacency + adjacency.T\n",
    "    return adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(5, 0.6, 9765)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (5, 0.6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(10, 0.4, 7648)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (10, 0.4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Use the function to create a random Erdos-Renyi graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba= n_edges/(n_nodes*(n_nodes-1)/2)\n",
    "randomER= erdos_renyi(n_nodes,proba)\n",
    "plt.spy(randomER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "We chose the same number of nodes as our graph. In order to have a similar number of edges as our graph, we chose the probability to be the number of edges divided by the maximum number of edges possible for a graph on n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The probability chosen is ',round(proba,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Create a function that constructs a Barabási-Albert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barabasi_albert(n, m, m0=2, seed=None):\n",
    "    \"\"\"Create an instance from the Barabasi-Albert graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    m: int\n",
    "        Number of edges to attach from a new node to existing nodes.\n",
    "    m0: int (optional)\n",
    "        Number of nodes for the inital connected network.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert m <= m0\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    adjacency = np.zeros([n, n], dtype=int)\n",
    "    degree = np.zeros(n, dtype=int)\n",
    "\n",
    "    # generate initial connected network with one edge per added node. (m0-1 edges)\n",
    "    #this is to have a connected graph\n",
    "    for i in range(1, m0):\n",
    "        target = np.random.choice(i, 1)\n",
    "        adjacency[i, target] = adjacency[target, i] = 1\n",
    "        degree[i] += 1\n",
    "        degree[target] += 1\n",
    "\n",
    "    # Grow network\n",
    "    for i in range(m0, n):\n",
    "        # Preferential attachment: probability that the new node connects to node i \n",
    "        dist = degree[:i] / np.sum(degree[:i])\n",
    "\n",
    "        # Choose m links without replacement with given probability distribution\n",
    "        targets = np.random.choice(i, m, replace=False, p=dist)\n",
    "        adjacency[i,targets] = adjacency[targets, i] = 1\n",
    "        degree[i] += m\n",
    "        degree[targets] += 1\n",
    "\n",
    "    # sanity check\n",
    "    assert np.array_equal(degree, np.sum(adjacency, axis=0))\n",
    "\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(5, 1, 2, 9087)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (5, 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(10, 2, 3, 8708)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (10, 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Use the function to create a random Barabási-Albert graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = 25 # this needs to be bigger than m\n",
    "m = int((n_edges - m0 +1) / (n_nodes - m0)) #to have similar number of edges than in our graph\n",
    "randomBA = barabasi_albert(n_nodes, m, m0, 8708)\n",
    "plt.spy(randomBA)\n",
    "plt.title('Barabasi-Albert ({}, {}, {})'.format(n_nodes, m, m0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the number of edges that should be added for each node (the value m) so that the total number of edges would be similar to the one of our wikipedia graph, depending on the number of initial nodes (m0) in the BA process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Compare the number of edges in all three networks (your real network, the Erdős–Rényi network, and the Barabási-Albert netowk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ER = int(np.sum(randomER)/2)\n",
    "m_BA = int(np.sum(randomBA)/2)\n",
    "m_wiki = n_edges\n",
    "\n",
    "print('The number of edges in the Erdos-Renyi network is ', m_ER)\n",
    "print('The number of edges in the Barabási-Albert network is ', m_BA)\n",
    "print('The number of edges in our wiki network is ', m_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of edges cannot be controlled precisely, we have fixed number of nodes. However, it is close enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a function that computes the [Kullback–Leibler (KL) divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between two probability distributions.\n",
    "We'll use it to compare the degree distributions of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    \"\"\"Compute the KL divergence between probability distributions of degrees of two networks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: np.array\n",
    "        Probability distribution of degrees of the 1st graph.\n",
    "    q: np.array\n",
    "        Probability distribution of degrees of the 2nd graph.\n",
    "    Returns\n",
    "    -------\n",
    "    kl\n",
    "        The KL divergence between the two distributions.\n",
    "    \"\"\"\n",
    "    # select the number of degrees that are occuring in the network\n",
    "    idx_nonzero_p = np.nonzero(p)\n",
    "    idx_nonzero_q = np.nonzero(q)\n",
    "    idx_nonzero = np.intersect1d(idx_nonzero_p, idx_nonzero_q)\n",
    "    \n",
    "    # now only select those indices\n",
    "    p = p[idx_nonzero]\n",
    "    q = q[idx_nonzero]\n",
    "    # now normalise the values so they sum up to 1 and rebecome probability distributions\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    kl= np.dot(p, np.log(p/q))\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array([0.2, 0.2, 0.2, 0.4])\n",
    "q_test = np.array([0.3, 0.3, 0.1, 0.3])\n",
    "round(kl_divergence(p_test, q_test),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same result as wikipedia examle\n",
    "p_test = np.array([0.36,0.48,0.16])\n",
    "q_test = np.array([0.333,0.333,0.333])\n",
    "round(kl_divergence( q_test, p_test),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce 0\n",
    "round(kl_divergence( np.array([0.1, 0, 0.7, 0.2]), np.array([0, 0.6, 0.2, 0.2])),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same distrib\n",
    "round(kl_divergence(np.array([0, 1]), np.array([0,1])),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: \n",
    "\n",
    "Compare the degree distribution of your network to each of the two synthetic ones, in terms of KL divergence.\n",
    "\n",
    "**Hint:** Make sure you normalise your degree distributions to make them valid probability distributions.\n",
    "\n",
    "**Hint:** Make sure none of the graphs have disconnected nodes, as KL divergence will not be defined in that case. If that happens with one of the randomly generated networks, you can regenerate it and keep the seed that gives you no disconnected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(degree, network_type):\n",
    "    '''\n",
    "    degree list: the list of node degrees\n",
    "    network_type: string used for plotting the title\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    bins = min(int(np.max(degree) - np.min(degree)), 100)\n",
    "    a = plt.hist(degree, log = True, bins=bins, density=True)\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Probability of node having degree k')\n",
    "    plt.title('Degree distribution for '+ network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this returns a tuple formed out of two arraysL array1 is the degree distribution, array2 is the degree number\n",
    "def return_hist(degrees, sequence = None):\n",
    "    '''\n",
    "    degrees: degree distribution of our graph\n",
    "    sequence: if not None, it defines the bin edges of the histogram\n",
    "    '''\n",
    "    if sequence is None:\n",
    "        max_degree = max(degrees)\n",
    "        sequence = np.arange(max_degree+2)\n",
    "    return np.histogram(degrees, sequence, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree distribution of our network \n",
    "degree_wiki=np.sum(adjacency, axis=0)\n",
    "degree_distribution_wiki= return_hist(degree_wiki)[0]\n",
    "\n",
    "#compute degree distribution Erdos Renyi Graph\n",
    "degree_ER=np.sum(randomER, axis =0)\n",
    "degree_distribution_ER= return_hist(degree_ER)[0]\n",
    "\n",
    "#degree distribution Barabási-Albert\n",
    "degree_BA=np.sum(randomBA, axis =0)\n",
    "degree_distribution_BA= return_hist(degree_BA)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the kl divergence on the degree distributions without binning them first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The kl divergence between the degree distribution of our network and ER is ',round(kl_divergence(degree_distribution_wiki, degree_distribution_ER),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The kl divergence between the degree distribution of our network and BA is ', round(kl_divergence(degree_distribution_wiki, degree_distribution_BA),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree distribution of BA is closer to our network than ER in terms of KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because there are many zeroes, we can bin the degree distributions and compare them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one binning model would be logarithm, and that would make more sense because the smaller degrees would be binner into smaller bins and larger degrees into larger bins\n",
    "rightmost_edge = np.max(np.array([max(degree_BA), max(degree_ER),max(degree_wiki) ]))\n",
    "binning = np.unique(np.ceil(np.geomspace(1, rightmost_edge)))\n",
    "degree_wiki_log = return_hist(degree_wiki, binning)[0]\n",
    "degree_BA_log = return_hist(degree_BA, binning)[0]\n",
    "degree_ER_log = return_hist(degree_ER, binning)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The kl divergence between the degree distribution of our network and ER is ', round(kl_divergence(degree_wiki_log, degree_ER_log),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The kl divergence between the degree distribution of our network and BA is ', round(kl_divergence(degree_wiki_log, degree_BA_log),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is even more clear that BA degree distribution is closer that ER distribution to our network.\n",
    "\n",
    "That is because the KL metric zeros out degrees that have probability 0 in either of the distributions. As we increase the degree, the distribution is more and more sparse, so it is unlikely the similarity of higher degrees is captured.\n",
    "Applying logarithmic binning diminishes this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering the build up process of Wikipeda it resembles a lot the Barabasi-Albert graph construction.\n",
    "You start with an initial set of articles and new articles are added which link to existing articles with a higher probability to link to a popular article (preferential attachment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Plot the degree distribution historgrams for all three networks. Are they consistent with the KL divergence results? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_ER, 'Erdos-Renyi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_BA, 'Barabási-Albert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_wiki, 'Wikipedia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that the degree distribution of our network is more similar to the degree distribution of Barabasi-Albert, which is coherent with the results indicated by the K-L divergence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Imagine you got equal degree distributions. Would that guarantee you got the same graph? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily, we can prove by a counter-example. The following graphs are not isomorphic, but have the same degree distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = np.array([\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0]\n",
    "])\n",
    "plt.spy(G1)\n",
    "plt.title('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = np.array([\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0]\n",
    "])\n",
    "plt.spy(G2)\n",
    "plt.title('G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(G1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(G2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "**You are allowed to use any additional library here (e.g., NetworkX, PyGSP, etc.).** Be careful not to include something here and use it in part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose a random network model that fits you network well. Explain your choice. \n",
    "\n",
    "**Hint:** Check lecture notes for different network models and their properties. Your choice should be made based on at least one property you'd expect to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared several models stated in the slides with our graph using different properties (number of nodes, edges, clustering coefficient, diameter, degree distribution) and we found that the BA model is the one that fits our graph the best. However, since it is not allowed to use the BA model again, we checked the networkX database for new models and we found one that would fit in theory even better: powerlaw_cluster_graph. \n",
    "The BA model was pretty close to our graph (number of nodes and edges, similar diameter, similar type of degree distribution) but the clustering coefficients were very different from ours. This algorithm includes a variable p (see below) that can return higher average clustering coefficient if p is large enough. Hence, we expect the clustering coefficient and the degree distribution to be similar to our graph (or at least better than with BA and ER models). We are also going to test the basic properties stated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Explain (in short) how the chosen model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The powerlaw_cluster_graph is an improvement of the BA model that takes into account a \"Probability of adding a triangle after adding a random edge\" which is clearly related to the clustering coefficient (the higher this probability is, the more it increases clustering coefficient in the graph). The variables for the function are the number of nodes n, the number of new edges m to add at each iteration and the probability p stated above. \n",
    "\n",
    "It starts with a graph of m nodes and no links. At each iteration, one node and m edges are added. The m edges are attached with preferential attachment (higher degree nodes will tend to have more edges) and with respect to a \"clustering step\": if possible and according to a probability p, new triangles will be created around the nodes, increasing the clustering coefficient. It stops when the number of nodes in the graph is n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Create a random graph from that model, such that the number of nodes is the same as in your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a temp graph with networkX to find the average clustering coefficient\n",
    "tempG = nx.from_numpy_array(adjacency)\n",
    "average_cluster_coeff_wiki = nx.algorithms.average_clustering(tempG)\n",
    "print('The average clustering coeff of our wikipedia network is ', round(average_cluster_coeff_wiki, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_clustcoeff=nx.powerlaw_cluster_graph(n_nodes, m,average_cluster_coeff_wiki , seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjG_clustcoeff=nx.to_numpy_array(G_clustcoeff)\n",
    "plt.spy(adjG_clustcoeff)\n",
    "plt.title('Power law cluster graph with p=average clustering coefficient ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.algorithms.average_clustering(G_clustcoeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is still very low compared to our average clustering coefficient. Hence, we played with the value p and found out that p=1 is the best value to have similar clustering coefficient: we created a second model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_p1=nx.powerlaw_cluster_graph(n_nodes, m, 1 , seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjG_p1=nx.to_numpy_array(G_clustcoeff)\n",
    "plt.spy(adjG_p1)\n",
    "plt.title('Power law cluster graph with p=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.algorithms.average_clustering(G_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is way more similar to the average clustering coefficient that we would like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Check the properties you expected to be similar, and compare to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of edges and nodes in G\n",
    "edgesG_p1=len(G_p1.edges())\n",
    "print('The number of edges in the random graph is {} and the one in our graph is {}'.format(edgesG_p1,n_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the average clustering coefficient of the random graph\n",
    "average_cluster_coeff_G_p1=nx.algorithms.average_clustering(G_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The average clustering coefficient of our network is {:.5f} and the average clustering coefficient of the random network G is {:.5f}'.format(average_cluster_coeff_wiki,average_cluster_coeff_G_p1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The average clustering coefficient for the BA model we constructed is 0.03536 and the one from BA model of networkx is 0.03530. The average clustering coefficient of the random graph we are considering now with the new model with p=1 is much closer to the average clustering coefficient of the wikipedia network, which is what we were trying to aim (see conclusion at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the degrees in the Graphs\n",
    "degree_G_p1=np.sum(adjG_clustcoeff, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The average degree in our wikipedia network is {:.2f}'.format(np.sum(degree_wiki)/n_nodes))\n",
    "print ('The average degree in the random network with p = 1 is {:.2f}'.format(np.sum(degree_G_p1)/n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two average degree are very similar, as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_G_p1, 'Random graph with p=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_distribution_G_p1 = return_hist(degree_G_p1)[0]\n",
    "\n",
    "#compare distributions with KL divergence\n",
    "\n",
    "print(kl_divergence(degree_distribution_wiki,degree_distribution_G_p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is larger than when comparing with BA model. However, it is still low compared with ER model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networkx format  \n",
    "Graph_wiki=nx.from_numpy_matrix(adjG_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_wiki=nx.diameter(Graph_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_G_p1=nx.diameter(G_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the diameter of the wikipedia network is {}'.format(diam_wiki))\n",
    "print('the diameter of the random network is {}'.format(diam_G_p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results what you expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.** \n",
    "\n",
    "The number of nodes are the same (obviously) and the number of edges are similar (we cannot have exactly the same number of edges but they are close enough). \n",
    "\n",
    "The diameters are not as similar as we thought would be. Indeed, adding this clustering property reduce the diameter (we have more clusters, hence less paths of longer lengths if everything is clustered around some hubs). The BA model had more similar diameter. \n",
    "\n",
    "We expected the clustering coefficients of the model using p=average clustering coefficient to be higher and closer to the ones of our graph. We were surprised, but when we realized that p=1 was a great value we decided to keep the analysis with this one. A higher value for p increases the clustering coefficient (as it increases the probability of creating triangles). Choosing p=1 was hence a good fit because wikipedia is a really dense graph, in the sense that hubs have very high clustering coefficient. The value p=1 sort of force nodes that have almost triangles formed around them to \"finish\" the triangles, and hence get really high clustering coefficient. \n",
    "\n",
    "The degree distribution, that we compared with KL divergence, are pretty similar, but not as good as the BA results we got in part 1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
