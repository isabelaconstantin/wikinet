{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 2: network models\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Hermina Petric Maretic](https://people.epfl.ch/hermina.petricmaretic), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students\n",
    "\n",
    "* Team: 37\n",
    "* Students: Isabela Constantin, Adélie Garin, Celia Hacker, Michael Spieler\n",
    "* Dataset: Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* In the first part, you cannot import any other library than we imported. In the second part, you are allowed to import any library you want.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this milestone is to explore various random network models, analyse their properties and compare them to your network. In the first part of the milestone you will implement two random graph models and try to fit them to your network. In this part you are not allowed to use any additional package. In the second part of the milestone you will choose a third random graph model that you think shares some properties with your network. You will be allowed to use additional packages to construct this network, but you must explain your network choice. Finally, make your code as clean as possible, and keep your textual answers short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0\n",
    "\n",
    "Import the adjacency matrix of your graph that you constructed in milestone 1, as well as the number of nodes and edges of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the adjacency matrix we will work with is the adjacency matrix of the largest weakly connected component \n",
    "adjacency_disconnected =  np.load('adjacency_undirected.npz')['arr_0'] # the adjacency matrix\n",
    "adjacency = np.load('largest_wcc.npz')['arr_0'] \n",
    "n_nodes =  adjacency.shape[0] # the number of nodes in the network\n",
    "n_edges =  int(np.sum(adjacency)/2) # the number of edges in the network\n",
    "print('the network has {} nodes and {} edges'.format(n_nodes, n_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "**For the computation of this part of the milestone you are only allowed to use the packages that have been imported in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Create a function that constructs an Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def erdos_renyi(n, proba, seed=None):\n",
    "    \"\"\"Create an instance from the Erdos-Renyi graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    p: float\n",
    "        Edge probability. A number between 0 and 1.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    adjacency = np.zeros((n,n))\n",
    "    adjacency[np.triu_indices(n, k=1)] = np.random.choice(2, int(n*(n-1)/2), p=[1-proba, proba])\n",
    "    adjacency = adjacency + adjacency.T\n",
    "    return adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(5, 0.6, 9765)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (5, 0.6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(10, 0.4, 7648)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (10, 0.4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Use the function to create a random Erdos-Renyi graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba= n_edges/(n_nodes*(n_nodes-1)/2)\n",
    "randomER= erdos_renyi(n_nodes,proba)\n",
    "plt.spy(randomER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "We chose the same number of nodes as our graph. In order to have a similar number of edges as our graph, we chose the probability to be the number of edges divided by the maximum number of edges possible for a graph on n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Create a function that constructs a Barabási-Albert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def barabasi_albert(n, m, m0=2, seed=None):\n",
    "    \"\"\"Create an instance from the Barabasi-Albert graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    m: int\n",
    "        Number of edges to attach from a new node to existing nodes.\n",
    "    m0: int (optional)\n",
    "        Number of nodes for the inital connected network.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert m <= m0\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    adjacency = np.zeros([n, n], dtype=int)\n",
    "    degree = np.zeros(n, dtype=int)\n",
    "\n",
    "    # generate initial connected network with one edge per added node. (m0-1 edges)\n",
    "    #this is to have a connected graph\n",
    "    for i in range(1, m0):\n",
    "        target = np.random.choice(i, 1)\n",
    "        adjacency[i, target] = adjacency[target, i] = 1\n",
    "        degree[i] += 1\n",
    "        degree[target] += 1\n",
    "\n",
    "    # Grow network\n",
    "    for i in range(m0, n):\n",
    "        # Preferential attachment: probability that the new node connects to node i \n",
    "        dist = degree[:i] / np.sum(degree[:i])\n",
    "\n",
    "        # Choose m links without replacement with given probability distribution\n",
    "        targets = np.random.choice(i, m, replace=False, p=dist)\n",
    "        adjacency[i,targets] = adjacency[targets, i] = 1\n",
    "        degree[i] += m\n",
    "        degree[targets] += 1\n",
    "\n",
    "    # sanity check\n",
    "    assert np.array_equal(degree, np.sum(adjacency, axis=0))\n",
    "\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(5, 1, 2, 9087)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (5, 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(10, 2, 3, 8708)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (10, 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Use the function to create a random Barabási-Albert graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = 25 #corresponds to number of hubs with degree higher than 400\n",
    "m = int((n_edges - m0 +1) / (n_nodes - m0)) #to have similar number of edges than in our graph\n",
    "randomBA = barabasi_albert(n_nodes, m, m0, 8708)\n",
    "plt.spy(randomBA)\n",
    "plt.title('Barabasi-Albert ({}, {}, {})'.format(n_nodes, m, m0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the number of edges that should be added for each node (the value m) so that the total number of edges would be similar to the one of our wikipedia graph, depending on the number of initial nodes (m0) in the BA process. To decide on the number of initial nodes, we chose to look at the number of big hubs in our graph, so that we would have something similar in the BA random graph. We decided on a threshold for the number of nodes with more than 400 as degree, there are 25 of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Compare the number of edges in all three networks (your real network, the Erdős–Rényi network, and the Barabási-Albert netowk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ER = int(np.sum(randomER)/2)\n",
    "m_BA = int(np.sum(randomBA)/2)\n",
    "m_wiki = n_edges\n",
    "\n",
    "print('The number of edges in the Erdos-Renyi network is ', m_ER)\n",
    "print('The number of edges in the Barabási-Albert network is ', m_BA)\n",
    "print('The number of edges in our wiki network is ', m_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a function that computes the [Kullback–Leibler (KL) divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between two probability distributions.\n",
    "We'll use it to compare the degree distributions of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    \"\"\"Compute the KL divergence between probability distributions of degrees of two networks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: np.array\n",
    "        Probability distribution of degrees of the 1st graph.\n",
    "    q: np.array\n",
    "        Probability distribution of degrees of the 2nd graph.\n",
    "    Returns\n",
    "    -------\n",
    "    kl\n",
    "        The KL divergence between the two distributions.\n",
    "    \"\"\"\n",
    "    # select the number of degrees that are occuring in the network\n",
    "    idx_nonzero_p = np.nonzero(p)\n",
    "    idx_nonzero_q = np.nonzero(q)\n",
    "    idx_nonzero = np.intersect1d(idx_nonzero_p, idx_nonzero_q)\n",
    "    \n",
    "    # now only select those indices\n",
    "    p = p[idx_nonzero]\n",
    "    q = q[idx_nonzero]\n",
    "    # now normalise the values so they sum up to 1 and rebecome probability distributions\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    kl= np.dot(p, np.log(p/q))\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array([0.2, 0.2, 0.2, 0.4])\n",
    "q_test = np.array([0.3, 0.3, 0.1, 0.3])\n",
    "kl_divergence(p_test, q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same result as wikipedia examle\n",
    "p_test = np.array([0.36,0.48,0.16])\n",
    "q_test = np.array([0.333,0.333,0.333])\n",
    "kl_divergence( q_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce 0\n",
    "kl_divergence( np.array([0.1, 0, 0.7, 0.2]), np.array([0, 0.6, 0.2, 0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same distrib\n",
    "kl_divergence(np.array([0, 1]), np.array([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: \n",
    "\n",
    "Compare the degree distribution of your network to each of the two synthetic ones, in terms of KL divergence.\n",
    "\n",
    "**Hint:** Make sure you normalise your degree distributions to make them valid probability distributions.\n",
    "\n",
    "**Hint:** Make sure none of the graphs have disconnected nodes, as KL divergence will not be defined in that case. If that happens with one of the randomly generated networks, you can regenerate it and keep the seed that gives you no disconnected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this returns a tuple formed out of two arraysL array1 is the degree distribution, array2 is the degree number\n",
    "def return_hist(degrees, sequence = None):\n",
    "    '''\n",
    "    degrees: degree distribution of our graph\n",
    "    sequence: if not None, it defines the bin edges of the histogram\n",
    "    '''\n",
    "    if sequence is None:\n",
    "        max_degree = max(degrees)\n",
    "        sequence = np.arange(max_degree+2)\n",
    "    # # + 2: comes from +1 due to arange and +1 for defining the rightmost edge of the bins\n",
    "    return np.histogram(degrees, sequence, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#degree distribution of our network \n",
    "degree_wiki=np.sum(adjacency, axis=0)\n",
    "degree_distribution_wiki= return_hist(degree_wiki)[0]\n",
    "\n",
    "#compute degree distribution Erdos Renyi Graph\n",
    "degree_ER=np.sum(randomER, axis =0)\n",
    "degree_distribution_ER= return_hist(degree_ER)[0]\n",
    "\n",
    "#degree distribution Barabási-Albert\n",
    "degree_BA=np.sum(randomBA, axis =0)\n",
    "degree_distribution_BA= return_hist(degree_BA)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the kl divergence on the degree distributions without binning them first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The kl divergence between the degree distribution of our network and ER is ',round(kl_divergence(degree_distribution_wiki, degree_distribution_ER),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The kl divergence between the degree distribution of our network and BA is ', round(kl_divergence(degree_distribution_wiki, degree_distribution_BA),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree distribution of BA is closer to our network than ER in terms of KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because there are many zeroes, we can bin the degree distributions and compare them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one binning model would be logarithm, and that would make more sense because the smaller degrees would be binner into smaller bins and larger degrees into larger bins\n",
    "rightmost_edge = np.max(np.array([max(degree_BA), max(degree_ER),max(degree_wiki) ]))\n",
    "binning = np.unique(np.ceil(np.geomspace(1, rightmost_edge)))\n",
    "degree_wiki_log = return_hist(degree_wiki, binning)[0]\n",
    "degree_BA_log = return_hist(degree_BA, binning)[0]\n",
    "degree_ER_log = return_hist(degree_ER, binning)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence(degree_wiki_log, degree_ER_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence(degree_wiki_log, degree_BA_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is even more clear that BA degree distribution is closer that ER distribution to our network.\n",
    "\n",
    "That is because the KL metric zeros out degrees that have probability 0 in either of the distributions. As we increase the degree, the distribution is more and more sparse, so it is unlikely the similarity of higher degrees is captured.\n",
    "Applying logarithmic binning diminishes this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Plot the degree distribution historgrams for all three networks. Are they consistent with the KL divergence results? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution(degree, network_type):\n",
    "    '''\n",
    "    degree list: the list of node degrees\n",
    "    network_type: string used for plotting the title\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    bins = min(int(np.max(degree) - np.min(degree)), 100)\n",
    "    a = plt.hist(degree, log = True, bins=bins, density=True)\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Probability of node having degree k')\n",
    "    plt.title('Degree distribution for '+ network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_wiki, 'wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_ER, 'Erdos-Renyi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_BA, 'Barabási-Albert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that the degree distribution of our network is closer to the degree dist of Barabasi-Albert, according to the results indicated by the K-L divergence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Imagine you got equal degree distributions. Would that guarantee you got the same graph? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily, we can prove by a counter-example. The following graphs are not isomorphic, but have the same degree distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = np.array([\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0]\n",
    "])\n",
    "plt.spy(G1)\n",
    "plt.title('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = np.array([\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0]\n",
    "])\n",
    "plt.spy(G2)\n",
    "plt.title('G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(G1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(G2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "**You are allowed to use any additional library here (e.g., NetworkX, PyGSP, etc.).** Be careful not to include something here and use it in part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose a random network model that fits you network well. Explain your choice. \n",
    "\n",
    "**Hint:** Check lecture notes for different network models and their properties. Your choice should be made based on at least one property you'd expect to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking and testing several different models, we think that the BA model is actually a good one for us. Indeed, it is scale free (i.e. the degree distribution follows a power law) as the wikipedia network. Another scale free model is the Watts-Strogatz, but this one returns too homogeneous degrees, not as wikipedia. Hence our choice of BA model, which is used to modelize a lot of internet-like networks. \n",
    "\n",
    "BA models have big hubs and then smaller hubs attached to them, exactly like wikipedia. Deleting one big hub should not change the connectivity of the graph (as wikipedia) but deleting the majority of big hubs would disconnect it. \n",
    "\n",
    "For those reasons we think the BA model fits our graph well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Explain (in short) how the chosen model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables for the BA model are a number of nodes m0 and a fixed number of edges m that can be attached at each iteration. The initial settings can differ: In our model of question 3, we start with a connected graph of m0 nodes and m0-1 edges and then we do the iteration process of attaching m nodes to the existing nodes, following a distribution that depends on the degree of each node, if the degree is already high then the edge has a larger probability to be attached to it. The BA model in Networkx has the same type of iteration process but start with m0 nodes and NO initial edges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Create a random graph from that model, such that the number of nodes is the same as in your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we created two BA models, one with our previous function and one with the networkx function. \n",
    "\n",
    "#previous model\n",
    "plt.spy(randomBA)\n",
    "plt.title('our Barabasi-Albert model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networkx\n",
    "G_networkBA= nx.barabasi_albert_graph(n_nodes, m)\n",
    "networkBA=nx.to_numpy_array(G_networkBA)\n",
    "plt.spy(networkBA)\n",
    "plt.title('Barabasi-Albert from Networkx')\n",
    "\n",
    "#note that our model has the big hubs first, hence the difference in the matrices. \n",
    "#This comes from the construction of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Check the properties you expected to be similar, and compare to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of nodes and edges in the three networks\n",
    "n_edges_randomBA = int(np.sum(randomBA)/2)\n",
    "n_edges_networkBA = int(np.sum(networkBA)/2)\n",
    "\n",
    "print('The number of edges in our original newtork is {}, in the BA model from networkx the number is {} and in our BA model it is {}'.format(n_edges, n_edges_networkBA, n_edges_randomBA)) #check degree distribution follows a power law. similar number of edges, same number of nodes. \n",
    "\n",
    "print('The number of nodes are the same, as we and networkx constructed the algorithm for BA based on the number of nodes.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the average clustering coefficients of the three networks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use the sparse matrix power function from milestone 1\n",
    "def sparse_matrix_pow(A, k):\n",
    "    As = sparse.csr_matrix(A)\n",
    "    tmp = As\n",
    "    for i in range(k-1):\n",
    "        tmp = tmp*As\n",
    "    As = tmp\n",
    "    Ad = np.empty(A.shape, dtype=A.dtype)\n",
    "    As.todense(out=Ad)\n",
    "    return Ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#average clustering coefficient in the three networks: \n",
    "#Function to compute the clustering coeff of a node, defined in milestone 1:\n",
    "def compute_clustering_coefficient(Adjacency, node, power_mat=None, degree=None):\n",
    "    \"\"\"Compute the clustering coefficient of a node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    node: int\n",
    "        The node whose clustering coefficient will be computed. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The clustering coefficient of the node. A number between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    if power_mat is None:\n",
    "        power_mat = sparse_matrix_pow(Adjacency, 3)\n",
    "    L = power_mat[node][node]/2\n",
    "    #for L we computed the number of triangles based at the node, this number divided by two gives the number of links between the neighbors of the node\n",
    "    if degree is None:\n",
    "        degree = np.sum(Adjacency, axis = 0)\n",
    "    k= degree[node]\n",
    "    if k in {0, 1}:\n",
    "        clustering_coefficient= 0\n",
    "    else:\n",
    "        clustering_coefficient= L*2/(k*(k-1))\n",
    "    return clustering_coefficient, power_mat, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to compute the average clustering coefficient in a network:\n",
    "\n",
    "def compute_average_coefficient(Adjacency):\n",
    "\n",
    "    average_clustering_coefficient=0\n",
    "    Adjacency_3=sparse_matrix_pow(Adjacency, 3) \n",
    "    N=len(Adjacency)\n",
    "    clustering_coeffs=np.zeros(N)\n",
    "    for i in range(N):\n",
    "        clustering_coeffs[i], _, _ = compute_clustering_coefficient(Adjacency, i, Adjacency_3) \n",
    "        average_clustering_coefficient+=clustering_coeffs[i]\n",
    "    \n",
    "    average_clustering_coefficient=average_clustering_coefficient/N\n",
    "    \n",
    "    return average_clustering_coefficient, clustering_coeffs  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adjacency matrix without self loops \n",
    "new_adjacency= adjacency-np.diag(np.diag(adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cluster_coeff_wiki, cluster_coeffs_wiki =compute_average_coefficient(new_adjacency)\n",
    "average_cluster_coeff_networkBA, cluster_coeffs_networkBA= compute_average_coefficient(networkBA)\n",
    "average_cluster_coeff_randomBA, cluster_coeffs_randomBA= compute_average_coefficient(randomBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The average clustering coeffcient of our network is {:.5f}, the average clustering coefficient of the networkx BA model is {:.5f} and the average clustering coefficient of our random BA is {:.5f}'.format(average_cluster_coeff_wiki,average_cluster_coeff_networkBA,average_cluster_coeff_randomBA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(cluster_coeffs_wiki, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(cluster_coeffs_randomBA, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(cluster_coeffs_networkBA, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree_wiki_new=np.sum(new_adjacency, axis=0)\n",
    "degree_randomBA=np.sum(randomBA, axis =0)\n",
    "degree_networkBA=np.sum(networkBA,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The average degree in our wikipedia network is {:.2f}'.format(np.sum(degree_wiki)/n_nodes))\n",
    "print ('The average degree in the Random BA network is {:.2f}'.format(np.sum(degree_randomBA)/n_nodes))\n",
    "print ('The average degree in the networkx BA network is {:.2f}'.format(np.sum(degree_networkBA)/n_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_wiki=nx.from_numpy_matrix(new_adjacency)\n",
    "G_randomBA=G=nx.from_numpy_matrix(randomBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diam_wiki=nx.diameter(G_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diam_randomBA=nx.diameter(G_randomBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diam_networkBA=nx.diameter(G_networkBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the diameter of the wikipedia network is {}'.format(diam_wiki))\n",
    "print('the diameter of the random BA network is {}'.format(diam_randomBA))\n",
    "print('the diameter of the networkx BA network is {}'.format(diam_networkBA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check degree distribution follows a power law. similar number of edges, same number of nodes. \n",
    "\n",
    "#do it on the 3 graphs and decide whether our model or networkx is better (for now we think ours will fit more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results what you expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
