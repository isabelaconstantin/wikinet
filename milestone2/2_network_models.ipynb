{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 2: network models\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Hermina Petric Maretic](https://people.epfl.ch/hermina.petricmaretic), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students\n",
    "\n",
    "* Team: 37\n",
    "* Students: Isabela Constantin, Adélie Garin, Celia Hacker, Michael Spieler\n",
    "* Dataset: Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* In the first part, you cannot import any other library than we imported. In the second part, you are allowed to import any library you want.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this milestone is to explore various random network models, analyse their properties and compare them to your network. In the first part of the milestone you will implement two random graph models and try to fit them to your network. In this part you are not allowed to use any additional package. In the second part of the milestone you will choose a third random graph model that you think shares some properties with your network. You will be allowed to use additional packages to construct this network, but you must explain your network choice. Finally, make your code as clean as possible, and keep your textual answers short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0\n",
    "\n",
    "Import the adjacency matrix of your graph that you constructed in milestone 1, as well as the number of nodes and edges of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the adjacency matrix we will work with is the adjacency matrix of the largest weakly connected component \n",
    "adjacency_disconnected =  np.load('adjacency_undirected.npz')['arr_0'] # the adjacency matrix\n",
    "adjacency = np.load('largest_wcc.npz')['arr_0'] \n",
    "n_nodes =  adjacency.shape[0] # the number of nodes in the network\n",
    "n_edges =  int(np.sum(adjacency)/2) # the number of edges in the network\n",
    "print('the network has {} nodes and {} edges'.format(n_nodes, n_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "**For the computation of this part of the milestone you are only allowed to use the packages that have been imported in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Create a function that constructs an Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos_renyi(n, proba, seed=None):\n",
    "    \"\"\"Create an instance from the Erdos-Renyi graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    p: float\n",
    "        Edge probability. A number between 0 and 1.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    adjacency = np.zeros((n,n))\n",
    "    adjacency[np.triu_indices(n, k=1)] = np.random.choice(2, int(n*(n-1)/2), p=[1-proba, proba])\n",
    "    adjacency = adjacency + adjacency.T\n",
    "    return adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(5, 0.6, 9765)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (5, 0.6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(10, 0.4, 7648)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (10, 0.4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Use the function to create a random Erdos-Renyi graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba= n_edges/(n_nodes*(n_nodes-1)/2)\n",
    "randomER= erdos_renyi(n_nodes,proba)\n",
    "plt.spy(randomER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "We chose the same number of nodes as our graph. In order to have a similar number of edges as our graph, we chose the probability to be the number of edges divided by the maximum number of edges possible for a graph on n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Create a function that constructs a Barabási-Albert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barabasi_albert(n, m, m0=2, seed=None):\n",
    "    \"\"\"Create an instance from the Barabasi-Albert graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    m: int\n",
    "        Number of edges to attach from a new node to existing nodes.\n",
    "    m0: int (optional)\n",
    "        Number of nodes for the inital connected network.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert m <= m0\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    adjacency = np.zeros([n, n], dtype=int)\n",
    "    degree = np.zeros(n, dtype=int)\n",
    "\n",
    "    # generate initial connected network with one edge per added node. (m0-1 edges)\n",
    "    #this is to have a connected graph\n",
    "    for i in range(1, m0):\n",
    "        target = np.random.choice(i, 1)\n",
    "        adjacency[i, target] = adjacency[target, i] = 1\n",
    "        degree[i] += 1\n",
    "        degree[target] += 1\n",
    "\n",
    "    # Grow network\n",
    "    for i in range(m0, n):\n",
    "        # Preferential attachment: probability that the new node connects to node i \n",
    "        dist = degree[:i] / np.sum(degree[:i])\n",
    "\n",
    "        # Choose m links without replacement with given probability distribution\n",
    "        targets = np.random.choice(i, m, replace=False, p=dist)\n",
    "        adjacency[i,targets] = adjacency[targets, i] = 1\n",
    "        degree[i] += m\n",
    "        degree[targets] += 1\n",
    "\n",
    "    # sanity check\n",
    "    assert np.array_equal(degree, np.sum(adjacency, axis=0))\n",
    "\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(5, 1, 2, 9087)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (5, 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(10, 2, 3, 8708)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (10, 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Use the function to create a random Barabási-Albert graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = 25 #corresponds to number of hubs with degree higher than 400\n",
    "m = int((n_edges - m0 +1) / (n_nodes - m0)) #to have similar number of edges than in our graph\n",
    "randomBA = barabasi_albert(n_nodes, m, m0, 8708)\n",
    "plt.spy(randomBA)\n",
    "plt.title('Barabasi-Albert ({}, {}, {})'.format(n_nodes, m, m0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the number of edges that should be added for each node (the value m) so that the total number of edges would be similar to the one of our wikipedia graph, depending on the number of initial nodes (m0) in the BA process. To decide on the number of initial nodes, we chose to look at the number of big hubs in our graph, so that we would have something similar in the BA random graph. We decided on a threshold for the number of nodes with more than 400 as degree, there are 25 of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Compare the number of edges in all three networks (your real network, the Erdős–Rényi network, and the Barabási-Albert netowk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ER = int(np.sum(randomER)/2)\n",
    "m_BA = int(np.sum(randomBA)/2)\n",
    "m_wiki = n_edges\n",
    "\n",
    "print('The number of edges in the Erdos-Renyi network is ', m_ER)\n",
    "print('The number of edges in the Barabási-Albert network is ', m_BA)\n",
    "print('The number of edges in our wiki network is ', m_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a function that computes the [Kullback–Leibler (KL) divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between two probability distributions.\n",
    "We'll use it to compare the degree distributions of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    \"\"\"Compute the KL divergence between probability distributions of degrees of two networks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: np.array\n",
    "        Probability distribution of degrees of the 1st graph.\n",
    "    q: np.array\n",
    "        Probability distribution of degrees of the 2nd graph.\n",
    "    Returns\n",
    "    -------\n",
    "    kl\n",
    "        The KL divergence between the two distributions.\n",
    "    \"\"\"\n",
    "    # select the number of degrees that are occuring in the network\n",
    "    idx_nonzero_p = np.nonzero(p)\n",
    "    idx_nonzero_q = np.nonzero(q)\n",
    "    idx_nonzero = np.intersect1d(idx_nonzero_p, idx_nonzero_q)\n",
    "    \n",
    "    # now only select those indices\n",
    "    p = p[idx_nonzero]\n",
    "    q = q[idx_nonzero]\n",
    "    # now normalise the values so they sum up to 1 and rebecome probability distributions\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    kl= np.dot(p, np.log(p/q))\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array([0.2, 0.2, 0.2, 0.4])\n",
    "q_test = np.array([0.3, 0.3, 0.1, 0.3])\n",
    "kl_divergence(p_test, q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same result as wikipedia examle\n",
    "p_test = np.array([0.36,0.48,0.16])\n",
    "q_test = np.array([0.333,0.333,0.333])\n",
    "kl_divergence( q_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce 0\n",
    "kl_divergence( np.array([0.3, 0, 0.7]), np.array([0, 0.6, 0.4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same distrib\n",
    "kl_divergence(np.array([0, 1]), np.array([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: \n",
    "\n",
    "Compare the degree distribution of your network to each of the two synthetic ones, in terms of KL divergence.\n",
    "\n",
    "**Hint:** Make sure you normalise your degree distributions to make them valid probability distributions.\n",
    "\n",
    "**Hint:** Make sure none of the graphs have disconnected nodes, as KL divergence will not be defined in that case. If that happens with one of the randomly generated networks, you can regenerate it and keep the seed that gives you no disconnected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this returns a tuple formed out of two arraysL array1 is the degree distribution, array2 is the degree number\n",
    "def return_hist(degrees, sequence = None):\n",
    "    if sequence is None:\n",
    "        max_degree = max(degrees)\n",
    "        sequence = np.arange(max_degree+2)\n",
    "    # # + 2: comes from +1 due to arange and +1 for defining the rightmost edge of the bins\n",
    "    return np.histogram(degrees, sequence, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree distribution of our network \n",
    "degree_wiki=np.sum(adjacency, axis=0)\n",
    "degree_distribution_wiki= return_hist(degree_wiki)[0]\n",
    "\n",
    "#compute degree distribution Erdos Renyi Graph\n",
    "degree_ER=np.sum(randomER, axis =0)\n",
    "degree_distribution_ER= return_hist(degree_ER)[0]\n",
    "\n",
    "#degree distribution Barabási-Albert\n",
    "degree_BA=np.sum(randomBA, axis =0)\n",
    "degree_distribution_BA= return_hist(degree_BA)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence(degree_distribution_wiki, degree_distribution_ER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence(degree_distribution_wiki, degree_distribution_BA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Plot the degree distribution historgrams for all three networks. Are they consistent with the KL divergence results? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(degree, network_type):\n",
    "    '''\n",
    "    degree list: the list of node degrees\n",
    "    network_type: string used for plotting the title\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    bins = min(int(np.max(degree) - np.min(degree)), 100)\n",
    "    a = plt.hist(degree, log = True, bins=bins, density=True)\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Probability of node having degree k')\n",
    "    plt.title('Degree distribution for '+ network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_wiki, 'wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_ER, 'Erdos-Renyi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(degree_BA, 'Barabási-Albert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that in fact the degree distribution of our network is closer to the degree dist of Barabasi-Albert, contrary to the results indicated by the K-L divergence. \n",
    "\n",
    "That is because the KL metric zeros out degrees that have probability 0 in either of the distributions. As we increase the degree, the distribution is more and more sparse, so it is unlikely the similarity of higher degrees is captured.\n",
    "We can try to apply logarithmic binning to see if the situation changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_wiki_log = return_hist(degree_wiki, np.geomspace(1, max(degree_wiki)))\n",
    "degree_BA_log = return_hist(degree_BA, np.geomspace(1, max(degree_BA)))\n",
    "degree_ER_log = return_hist(degree_ER, np.geomspace(1, max(degree_ER)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kl_divergence(degree_wiki_log[0], degree_ER_log[0] ))\n",
    "print(kl_divergence(degree_wiki_log[0], degree_BA_log[0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: BA is still further away. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Imagine you got equal degree distributions. Would that guarantee you got the same graph? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily, we can prove by a counter-example. The following graphs are not isomorphic, but have the same degree distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = np.array([\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0]\n",
    "])\n",
    "plt.spy(G1)\n",
    "plt.title('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = np.array([\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0]\n",
    "])\n",
    "plt.spy(G2)\n",
    "plt.title('G2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(G1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(G2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "**You are allowed to use any additional library here (e.g., NetworkX, PyGSP, etc.).** Be careful not to include something here and use it in part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose a random network model that fits you network well. Explain your choice. \n",
    "\n",
    "**Hint:** Check lecture notes for different network models and their properties. Your choice should be made based on at least one property you'd expect to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared several models stated in the slides with our graph using different properties (number of nodes, edges, clustering coefficient, diameter, degree distribution) and we found that the BA model is the one that fits our graph the best. However, since it is not allowed to use the BA model again, we checked the networkX database for new models and we found one that would fit in theory even better: powerlaw_cluster_graph. \n",
    "The BA model was pretty close to our graph (similar number of nodes and edges, similar diameter, similar degree distribution) but the clustering coefficients were very different from ours. This algorithm includes a variable p (see below) that can return higher average clusteing coefficient if p is large enough. Hence, we expect the clustering coefficient and the degree distribution to be similar to our graph (or at least better than with BA and ER models). We are also going to test the basic properties stated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Explain (in short) how the chosen model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The powerlaw_cluster_graph is an improvement of the BA model that takes into account a \"Probability of adding a triangle after adding a random edge\" which clearly related to the clustering coefficient. The variables for the function are the number of nodes n, the number of new edges m to add at each iteration and the probability p stated above. \n",
    "\n",
    "It starts with a graph of m nodes and no links. At each iteration, one node and m edges are added. The m nodes are attached with preferential attachment (higher degree nodes will tend to have more nee edges) and with respect to a \"clustering step\": if possible and according to a probability p, new triangles will be created around the nodes, increasing the clustering coefficient. It stops when the number of nodes in the graph is n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Create a random graph from that model, such that the number of nodes is the same as in your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the sparse matrix power function from milestone 1\n",
    "def sparse_matrix_pow(A, k):\n",
    "    As = sparse.csr_matrix(A)\n",
    "    tmp = As\n",
    "    for i in range(k-1):\n",
    "        tmp = tmp*As\n",
    "    As = tmp\n",
    "    Ad = np.empty(A.shape, dtype=A.dtype)\n",
    "    As.todense(out=Ad)\n",
    "    return Ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average clustering coefficient in the three networks: \n",
    "#Function to compute the clustering coeff of a node, defined in milestone 1:\n",
    "def compute_clustering_coefficient(Adjacency, node, power_mat=None, degree=None):\n",
    "    \"\"\"Compute the clustering coefficient of a node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    node: int\n",
    "        The node whose clustering coefficient will be computed. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The clustering coefficient of the node. A number between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    if power_mat is None:\n",
    "        power_mat = sparse_matrix_pow(Adjacency, 3)\n",
    "    L = power_mat[node][node]/2\n",
    "    #for L we computed the number of triangles based at the node, this number divided by two gives the number of links between the neighbors of the node\n",
    "    if degree is None:\n",
    "        degree = np.sum(Adjacency, axis = 0)\n",
    "    k= degree[node]\n",
    "    if k in {0, 1}:\n",
    "        clustering_coefficient= 0\n",
    "    else:\n",
    "        clustering_coefficient= L*2/(k*(k-1))\n",
    "    return clustering_coefficient, power_mat, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute the average clustering coefficient in a network:\n",
    "\n",
    "def compute_average_coefficient(Adjacency):\n",
    "\n",
    "    average_clustering_coefficient=0\n",
    "    Adjacency_3=sparse_matrix_pow(Adjacency, 3) \n",
    "    N=len(Adjacency)\n",
    "    clustering_coeffs=np.zeros(N)\n",
    "    for i in range(N):\n",
    "        clustering_coeffs[i], _, _ = compute_clustering_coefficient(Adjacency, i, Adjacency_3) \n",
    "        average_clustering_coefficient+=clustering_coeffs[i]\n",
    "    \n",
    "    average_clustering_coefficient=average_clustering_coefficient/N\n",
    "    \n",
    "    return average_clustering_coefficient, clustering_coeffs  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjacency matrix without self loops\n",
    "new_adjacency=adjacency-np.diag(np.diag(adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cluster_coeff_wiki, cluster_coeffs_wiki =compute_average_coefficient(new_adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.powerlaw_cluster_graph(n_nodes, m,average_cluster_coeff_wiki , seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjG=nx.to_numpy_array(G)\n",
    "plt.spy(adjG)\n",
    "plt.title('Random Graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Check the properties you expected to be similar, and compare to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COmpute the number of edges and nodes in G\n",
    "edgesG=np.sum(adjG)/2\n",
    "edgesNew=np.sum(new_adjacency)/2\n",
    "print('The number of edges in the random graph is {} and the number of edges in the original network is {}'.format(edgesG,n_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the average clustering coefficient of the random graph\n",
    "average_cluster_coeff_G, cluster_coeffs_G =compute_average_coefficient(adjG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The average clustering coeffcient of our network is {:.5f} and the average clustering coefficient of the random network G is {:.5f}'.format(average_cluster_coeff_wiki,average_cluster_coeff_G))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average cclustering coefficient for the BA model we constructed is 0.03536 and that of networkx is 0.03530. The average clustering coefficient of the random graph we are considering now is closer to the average clustering coefficient of the wikipedia network but still lower than what we expected it to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster_coeffs_G, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster_coeffs_wiki, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the degrees in the Graphs\n",
    "degree_wiki_new=np.sum(new_adjacency, axis=0)\n",
    "degree_G=np.sum(adjG, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The average degree in our wikipedia network is {:.2f}'.format(np.sum(degree_wiki)/n_nodes))\n",
    "print ('The average degree in the random network is {:.2f}'.format(np.sum(degree_G)/n_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the degree distribution \n",
    "plot_distribution(degree_G, 'Degree distribution G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare distributions with KL divergence\n",
    "print(kl_divergence(degree_distribution_wiki,degree_G ))\n",
    "# need to normalize and do degree distribution and stuff !!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networkx format  \n",
    "Graph_wiki=nx.from_numpy_matrix(new_adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_wiki=nx.diameter(Graph_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_G=nx.diameter(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the diameter of the wikipedia network is {}'.format(diam_wiki))\n",
    "print('the diameter of the random network is {}'.format(diam_G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results what you expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.** The number of nodes are the same (obviously) and the number of edges are similar (we cannot have exactly the same number of edges but they are close enough). The diameters are not as similar as we thought would be. Indeed, adding this clustering property reduce the diameter (we have more clusters, hence less paths of longer lengths if everything is clustered around some hubs. The BA model had more similar diameter. \n",
    "We expected the clustering coefficients of the model to be higher and closer to the ones of our graph. We think it has to do with the value p, a higher value increases the clustering coefficient (as it increases the probability of creating triangles). However, a higher value of p doesn't represent our wikipedia graph well anymore. \n",
    "Hence, we had the same expectation about the average clustering coefficient and it is lower than expected. \n",
    "The degree distribution, that we compared with KL divergence, are pretty similar. \n",
    "\n",
    "We conclude that this model fits our graph quite well, but it could be much improved at the level of clustering around one node (clustering coefficient)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
